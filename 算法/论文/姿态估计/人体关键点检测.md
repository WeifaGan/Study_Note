# 第一章 人体关键点检测基础

## 1.1 指标

### 1.1.1 OKS：

### $oks_p=\frac{\sum_iexp(-d^2_{pi}/2S^2_p\sigma^2_i)\delta(v_{pi}>0)}{\sum \delta(v_{pi}>0)}$

* $p$ 表示grouth truth中人的id为$p$
* $i$表示关键点的id为$i$
* $d_{pi}$为gt中的id=$p$的人中id=$i$的关键点与预测中的人的id=$i$关键点的欧氏距离
* $S_p$ 表示gt行人中id为$p$的人的尺度因子，其值为行人检测框面积的平方根。个人理解这里为了减少体积小的行人对关键点的敏感度。
* $\sigma_i$ 关键点归一化因子。$\sigma$的取值可以为：{鼻子：0.026，眼睛：0.025，耳朵：0.035，肩膀：0.079，手肘：0.072，手腕：0.062，臀部：0.107，膝盖：0.087，脚踝：0.089}
* $v_{pi}$ 表示关键点的可见性，$v_{pi}=0$表示关键点未标记，可能是不存在或者不知道在哪里，$v_{pi}=1$表示关键点无遮挡已标记，$v_{pi}=2$表示关键点有遮挡但有标记。预测关键点有两个属性$v_{pi}^{’}=0$表示没有预测出来，$v_{pi}^{’}=1$表示预测出来了。
* $\delta(*)$，若条件成立，$\delta(*)$为1，否则为0。这表示只计算有标记的关键点

### 1.1.2 OKS矩阵

如果一张图片M(M>1)个人，预测出N个的人体关键点，这时候就涉及到N*M的OKS矩阵OKS。矩阵中位置(i,j)表示预测的第i个人的关键点与GT的第i个人的关键点的OKS。

### 1.1.3 AP(Average Presicion)

**单人姿态：**$AP=\frac{\sum_p \delta(oks>T)}{\sum_p M}$,其中，$T$表示阈值，$M$表示一张GT的行人个数，在单人姿态估计中$M=1$ 。即大于阈值的人数/总人数

**多人姿态：** $AP=\frac{\sum_M \sum_p \delta(oks>T)}{\sum_M \sum_p M}$，设图片中GT中有M个人，预测出N个人，GT中每一个人都与N个人有oks，公式中的oks便是每个GT中的人在N个人匹配中最大的oks。

### 1.1.4 MAP(mean AP)

设定不同阈值，得到不同的AP，然后求平均。

## 1.2 训练集

* MPII（MPII Human Pose Dataset）：单人/多人人体关键点检测数据集，关键点个数为16，样本数25K，是单人人体关键点检测的主要数据集。

* MSCOCO：多人人体关键点检测数据集，关键点个数为17，样本数多于30W，多人关键点检测的主要数据集，主流数据集。
* AI Challenger：多人人体关键点检测数据集，关键点个数为14，样本数约38W，竞赛数据集。

## 1.3 人体关键点检测研究现状

* 传统的方法：
  * 传统方法主要通过图像结构来解决人体关键点检测，例如树模型，随机森林模型。还有算法是基于图模型，例如随机场模型和依赖图模型
  * PSM、GSM、DPM
* 深度学习
  * 单人：CPM、DeepPose、PAFs
  * 多人
    * 自低向上：
      * 检测速度快且预测时间与图片人数无关，但是对于图片的小尺寸人体容易漏检
      * DeepCut、DeeperCut、PAFs
    * 自顶向下：
      * 检测速度慢，预测时间随着人数的增加而线性地增加，但是不受尺度影响，平均精度和召回率都比较高
      * Mask R_CNN、CPN、RMPE

# 第二章 Pose Machines: Articulated Pose Estimation via Inference Machines

## 1.摘要

基于部位的图模型受限于树型结构和简单参数，并且它们简单的依赖关系很难捕获身体部位间的交互，作者不是对学习的图模型进行推理，而是在推理机的基础上提出关节姿态估计的方法，把多部位的丰富空间交互和不同尺度的部位信息融合在一起。

## 2.介绍

关节点姿态估计复杂原因：1.骨架具有大量的自由度，导致需要搜索的配置空间维度高。2.图中的人有很多变量。

为了解决这个复杂度，目前很多方法都是使用图模型来捕获各部位位置间的相关性和依赖关系。可以除了简单的模型，图模型的推理比较困难也不精准。图模型的另外一个问题是在指定交互类型时候，它需要仔细考虑潜在的函数。

作者的方法通过训练推理过程，避免复杂性和可行性的折中。推理机结构特别合适处理姿态估计的挑战，原因：1.同时融合了丰富的多变量(部位)交互，减少了二次计算的错误。第二，学习丰富的空间模型，不需要潜在函数特定的参数形式。第三，它的模型结构合适使用多个预测器，这样更合适处理每个部位多模态外观。

## 3.姿态推理机

## 3.1 Inference Machine(推理机)

推理机由一系列的多分类器组成$g_t(*)$。$g_t(*)$是用于预测每个部位(anatomical landmark，解剖标志)的图中位置。在每个阶段，分类器都为每个部位的位置预测一个置信度,定位为：
$$
b_t(Y_p=z)=g_t^p(x_z;\bigoplus_{i=1}^p \psi(z,b^i_{t-1}))
$$
其中，$b^p_{t-1}={b_{t-1}(Y_p=z)},z\in Z$是一个前面的分类器对第$p$个部位在每个位置$z$的置信度集合。特征函数$\psi$计算来自分类器先前的置信度的上下文特征。推理机的优点在于不需要对变量之间的依赖通过潜在函数进行显式建模(这个怎么理解？)

作者的关节点姿态估计方法采用了分层均值推理机的形式，其中每个变量(部位)使用的上下文信息来自图像中尺度和空间的相邻变量。

## 3.2 姿态推理机算法

### 3.2.1 合并层次结构

作者采用层级结构的推理机，如图1(b)所示，这类似于对图像中不同尺度的部位间的交互进行编码。层次机构的每个层级L都有不同类型的部位。在最粗糙的层次上，层级结构由捕获整个身体的一个部位组成，下一层则由对整个肢体建模的复合部位组成，而最精细的层级对解剖标记周围区域进行建模的小部位组成(应该就是从粗到细吧)。

![图1](https://gitee.com/weifagan/MyPic/raw/master/img/pose_machine.PNG)

​                                                                               图1

作者定义第$l$层的分类器表示为$\sideset_{^l}{}g_t(*)$。为了得到第一阶段的部位位置的置信度估计，$\sideset_{^l}{}g_1(*)$作为在图像位置$z$处提取的图像块计算的输入特征：
$$
{\sideset{^l}{}g}_1(X_z^l) \rightarrow {\sideset{^l}{}b}_1^p(Y_p=z)_{p\in0,...P_l}
$$
其中，${\sideset{^l}{}b}_1^p(Y_p=z)$表示分类器在第1阶段的第$l$层对第$p$个部位在图像位置$z$上的预测分数。在后续阶段，为了利用层次结构中的跨级别的上下文，预测被定义为：
$$
\sideset_{^l}{}g_t(x_z,\bigoplus_{i \in 1...L} \psi(z,\sideset_{^l}{} b_{t-1})) \rightarrow {\sideset{^l}{}b}_t^p(Y_p=z)_{p\in0,...P_l}
$$

### 3.2.2 上下文特征

为了得到每个部位相对于其邻域的置信度的空间相关性，定义两个于上下文有关的特征映射$\psi_1$$\psi_2$。

**上下文块特征：**$\psi_1(z,\sideset{^l}{}b_{t-1})=\bigoplus_{p\in{0,...P_l}}c_1(z,\sideset{^l}{}b_{t-1}^p)$，其中$c_1(z,\sideset{^l}{}b_{t-1}^p)$表示在$l$层的所有部位的置信度在位置$z$所提取和向量化的块(如图2(a))。换言之，上下文特征是在每一层所有部位的置信度映射的位置$z$所提取的分数的连接。

**上下文偏移映射：**各个部位之间的长距离交互可能是不均匀相对偏移的，为了对它就行编码，对第$l$层的所有部位采用非极大值抑制得到$K$个峰值的排序列表。$\sideset{^l}{}o_k^p$表示第$l$层的第$p$个部位的置信度映射中从位置$z$到第$k$个峰值在极坐标计算所得的偏移向量(如图2(b))。计算上下文偏移映射：
$$
\psi_2(z,\sideset{^l}{}b_{t-1})=\bigoplus_{p\in{1...P_l}}c_2(z,\sideset{^l}{}b_{t-1}^p)
$$
其中,$c_2(z,\sideset{^l}{}b_{t-1}^p)=[\sideset{^l}{}o_1^p,...\sideset{^l}{}o_K^p]$。

![](https://gitee.com/weifagan/MyPic/raw/master/img/pose_machine1.PNG)

​                                                                             图2

下文块特征$\psi_1$捕获关于相邻部分的置信度的粗略信息，而偏移特征$\psi$捕获精确的相对位置信息。最终的上下文特征 通过连接两个特征来计算的：$\psi()=[\psi_1;\psi_2]$

## 3.3 训练

以阶段性的方式进行训练，在训练集的图像中提取图像块作为数据集$D_0$，用$D_0$作为第一个阶段的训练集。在以后的阶段$t$中，数据集$D_t$从每张图片置信度映射${\sideset{^l}{}b_{t-1}}$的标记位置中提取上下文特征并进行连接。

## 3.4 堆叠

训练这样的推理过程容易过拟合。如果在在后续阶段都使用相同的数据集会导致过度依赖前阶段的上下文特征或者对特点额数据集过拟合。用前阶段的输出数据来训练后阶段的这样的堆叠方法来解决这个问题。具体的堆叠方法看得有点懵逼.....

## 3.5 推理

通过多阶段的推理可以看到计算的置信度越来越精细。每个部位的地位为：
$$
\forall l,\forall p,\sideset{^l}{}{y^*_p} = argmax_z\sideset{^l}{}{b^p_T(z)}
$$

# 4 总结和讨论

* 作者提出来层级结构的姿态机。每一层的部位输入大小尺度不同，这种部位多尺度输入能够提供更加丰富的空间交互信息，改善姿态估计性能。后一阶段的输入以前一阶段的输出为基础使得部位定位越来越精细。
* 对置信度上下文特征提取能获得部位的空间相关性

# 第三章 Convolutional Pose Machines(CPM)

# 1 摘要

姿态机提供的顺序预测框架可以学习丰富的隐含空间模型。作者把卷积网络合并到姿态机框架来学习图像特征和基于图像的空间模型。文章的贡献在于隐式地对变量间的长距离依赖进行建模。通过设计卷积网络组成的顺序结构来直接在上阶段的置信度映射进行操作来达到这个目的。

长距离依赖，个人理解就是距离比较远的关键点间在空间上是有依懒性，譬如头的点A，膝盖点B，B能活动的肯定有个范围，不可能去了无限远啊。

# 2 介绍

CPM继承了PM结构的优点：隐式学习图像和多部位组件的长距离依赖关系；学习和推理的紧密结合；模块顺序设计；CPM结合了PM优势和卷积结构的优势：直接从数据中学习图像和空间上下文的特征表达能力；允许反向传播进行全局联合训练的一种全可微的（differentiable）结构；有效处理大规模训练数据集的能力。

置信度映射为后续阶段提供了每个部位位置的空间不确定的非参数编码表达，让CPM学习基于图像的部位相关性的丰富空间模型(这个有点抽象哦，怎么理解呢)

前阶段为后阶段提供明确的线索，所以置信图对每个部位的位置估计越来越精细。作者发现更大的感受野对学习长距离的空间关系很重要。

CPMs自然地提出了一个系统性的架构，它定期地添加中间监督来补充梯度，进而引导网络产生精度不断提高的置信度映射。

本文中，作者展示了顺序预测框架如何利用置信度映射保留的不确定型对丰富的空间上下文进行编码，执行中间局部监督来解决提问消失问题。

# 3 Convolutional Pose Machines

## 3.1 姿态机(略)

## 3.2 CPM

### 3.2.1 使用局部图像信息定位关键点

![](https://gitee.com/weifagan/MyPic/raw/master/img/CPM.PNG)

​                                                                              图1

把输入的剪裁图像归一化到368x368，第一阶段最后的感受野为160x160。这阶段使用图像信息是局部的是因为这阶段感受野在比较小的区域。

### 3.2.2 带有空间上下文信息的级联预测

第一阶段对于具有外观一致性的关键点（例如头和肩膀）的检测率还是比较好的，但是对于在人体骨骼运动链中处于较低位置的关键点来说，精度要低很多，这是由于它们外观变化很大。(也就是说较低位置的关键点变化性较大，精度较低)。

网络设计的原则是第二阶段输出层的感受野足够大来学习部位间的潜在复杂性和长距离的相关性。

生成第一阶段heatmaps的网络以较小的感受野局部地处理图像，在第二阶段中我们设计了一个可以极大地增大有效感受野的网络。大的感受野可以通过池化操作得到（但要牺牲精度），也可以通过增大卷积核的尺寸来实现（会增加参数数量），也可以通过增加卷积层层数实现（训练的时候可能会遇到梯度消失的风险）

我们发现准确率会随着感受野的尺寸增大而提高。第二阶段的感受野大小相对于原图为400x400，能够覆盖任何一对关键点。

## 3.3 在CPM的学习

层数较多会导致梯度消失。

在每一层的输出都添加损失函数来解决梯度消失()。损失函数定义为：
$$
f_t=\sum_{p=1}^{P+1}\sum_{z\in Z}||b_t^p(z)-b_*^p(z)||_2^2
$$
$b_*^p(z)$为GT的heatmaps，由每个人体关键点p所在位置处高斯撒点生成。

整个目标有各阶段损失相加构成，如下公式：
$$
F=\sum_{t=1}^Tf_t
$$

# 4 评估 

## 4.1 分析

**解决梯度消失**：虽然整个网络有很多层，但是每个阶段的中间损失函数给梯度作补充。

# 5 结论和讨论

作者在实际的实现时，stage1和stage2都输入了原图，stage3开始不再输入原图进行图像特征的计算，而是直接对stage2的中间卷积特征进行再卷积来计算图像特征，实际实现的结构示意图如下图所示：

![](https://gitee.com/weifagan/MyPic/raw/master/img/CPM1.PNG)

* 作者尝试解决什么问题：
  * 把卷积网络融合到姿态机提出CPM算法，提升精确度。
* 关键元素：
  * 采用CPM的级联结构学习丰富的隐式空间模型。
  * 采用更大的感受野可捕获更多的context，学习部位间的潜在复杂性和长距离的相关性。
  * 每个阶段添加中间监督可以解决梯度消失问题，因为这样子对梯度作了补充。
* 为我所用：
  * 级联结构的思想
  * 感受野足够大来学习部位间的潜在复杂性和长距离的相关性。
  * 解决梯度消失的方法

# 第三章 DeepPose

## 3.1 摘要

姿态估计可以公式化为DNN关于人体关键点的回归问题。作者提出DNN回归的级联模型，可以得到高精度的姿态估计。

## 3.2 介绍

用整个图像输入的和7层CNN来每个人体关键点的位置回归有两个优点

* DNN 有捕获每个人体关键点的全部上下文信息
* 比图模型更容易实现

作者使用DNN级联结构的姿态预测器。这样子的级联可以使得关键点的定位更加精准。

## 3.3 深度学习模型的姿态估计

对关键点进行归一化，把绝对坐标转为相对坐标：
$$
N(x;b)=(1/b_w,0;0,1/h_h)(y_i-b_c)
$$

### 3.3.1 基于DNN回归的姿态估计

把姿态估计看做是回归问题，训练和使用函数$\psi(x;\theta)$对图片$x$回归为归一化的姿态向量。那么预测的坐标再转化为相对坐标来消除绝对坐标的影响(会有什么影响)：$y*=N^{-1}(\psi(N(x);\theta))$。当然这个函数$\psi(x;\theta)$其实就是DNN所能映射的一个函数。

论文中所使用的是网络层共7层所图1所示：

![](https://gitee.com/weifagan/MyPic/raw/master/img/deeppose.PNG)

​                                                                                                           图1

整个网络描述为：$C(55*55*96)-LRN-P-C(27*27*256)-LRN-P-C(13*13*384)-C(13*13*256)-P-F(4096)-F(4096)$

$LRN$”局部相应归一化：

损失函数：$L_2 \ loss$
$$
argmin_{\theta}\sum_{(x,y)\in D_{N}}\sum_{i=1}^k||y_i-\psi_i(x;\theta)||^2_2
$$


### 3.3.2 Pose 回归器的级联

前章节的姿态推理是基于整个图像的，所以它依赖于上下文。由于固定的输入大小是220x220，在较粗的尺度上捕获姿态的特性来学习滤波器，所以网络捕获细节的能力有限。为了得到更高精确度，级联一个姿态回归器(就是级联上一节的网络)图2所示。

![](https://gitee.com/weifagan/MyPic/raw/master/img/deeppose1.PNG)

网络的输入是前阶段的预测点附近的图像块。这样子后面的网络可以看到更高分辨率的图像，还可以从更精细的尺度学习特征。

Stage1:$y^1 \leftarrow N^{-1}(\psi (N(x;b^0);\theta_1);b^0)$

其中$b^0$是值整个图像或者是由检测器所得到的区域

Stage2:

$y_i^s \leftarrow y_i^{s-1}+N^{-1}(\psi (N(x;b);\theta_s);b)$

for $b=b_i^{s-1}$

$b_i^s \leftarrow (y_i^s,\sigma diam(y^s),\sigma diam(y^s))$



不单单只是利用前一阶段的预测，作者做了中间数据增强的处理。利用预测点在其邻域内生成多个关节点。该邻域使用的是二维高斯分布$N^{s−1}$,$δ$是从$N^{s−1}$取出的样本。这个数据增强不是很懂...

$D^s-A={(N(x;b);N(yi;b))|(x;yi)∼D;δ∼N(s−1)b=(yi+δ;σdiam(y))}$

loss函数：$\theta_s=argmin_{\theta}\sum_{(x,y_i)\in D^s_{A}}\sum_{i=1}^k||y_i-\psi_i(x;\theta)||^2_2$

## 3.4 总结和讨论

* 作者试图解决什么问题
  * 如何使用DNN来得到关键点更加精确的定位还没有确定的答案，作者尝试解答这个问题并提出简单有力的级联网络
* 论文的关键元素是什么
  * 级联网络，通过初始的网络层对关键点进行粗定位，再从预测点的领域图像块作为下一阶段的输入，再通过网络层进行精细定位
* 有什么地方可以“为我所用”或者值得借鉴的地方？
  * 级联网络的思路值得借鉴