# mAP计算指标

听说yolo-v5都来了，渣渣的我连yolo v1-v3的理解得不是特别到位，所以打算重新回顾一下yolo v1-v3 并学习v4-v5。那么就从目标检测的计算指标开始吧，我们一起来梳理一下mAP的计算。

在目标检测中，主要的计算指标是mAP(mean Average precision),意思是平均精确度。

## 查准率(precision)和查全率(recall)

在理解mAP之前先来理解一下查准率(precision)和查全率(recall)。假设有这样一个混淆矩阵：

|          | 预测       | 预测       |
| -------- | ---------- | ---------- |
| 真实情况 | 正例       | 反例       |
| 正例     | TP(真正例) | FN(假反例) |
| 反例     | FP(假反例) | TN(真反例) |

查准率，顾名思义，就是描述查得有多准的问题，说的就是我们预测的正例中实际上有多少个正例。譬如有100个样本，我们预测其中有50个样子都是正例，但是在这预测的50个正例中，40个是正例，有10个是反例，那么查准率就是40/50=80%。所以有
$$
precision = \frac{TP}{TP+FP}
$$
查全率，顾名思义，就是描述查得有多全的问题，说的就是有实际中的n个正例中有多少个样本被预测出来了。譬如我们有100个样本，包括50个正例，50个反例，我们只预测对了40个正例，50个正例中只有40个被预测出来了，那么查全率就是40/50=80%。所以有
$$
recall = \frac{TP}{TP+FN}
$$
查准率和查全率是一对矛盾的度量。一般来说，查全率高的时候，查准率往往偏低，而查准率高的时候，查全率往往也偏低。譬如有100个样本，其中包括1个正例，99个反例。我们预测它全部都是正例，那当然有100%的查全率，因为所以的正例都会被预测出来了。但是查准率就很低了，因为预测的100个正例中只有1一个被预测出来了，查准率只有1%。不管你是关注查全率还是查准率，都是比较片面，一般我们都有综合考虑，于是就有了P-R曲线。

P-R曲线能直观地显示出学习器在样本总体上的查全率和查准率，如下图所示。在P-R图中，可以比较曲线“包住”的面积或者平衡点(查全率=查准率)来判断哪个学习器性能更加优秀，很明显黄线的学习器性能更好。

![图1 P-R图](https://gitee.com/weifagan/MyPic/raw/master/img/PR_.png)



## 交并比

交并比IoU衡量的是两个区域的重叠程度，是两个区域重叠面积占总面积的比例(重叠面积只算一次)，如下图所示。

![图1 P-R图](https://gitee.com/weifagan/MyPic/raw/master/img/IOU1.png)





## 目标检测如何确定TP、FP、FN and confidence/sore

因为训练验证和测试都是一个个batch的，所以这里的TP、FP、FN都是batch计算的。

**TP**:一个正确的检测，检测的IOU>=Threshold并且置信度大于阈值，即预测的边界框中分类正确并且边界框坐标达标的数量。如果一个ground truth有很多个预测框，那么选择IOU最高的预测框作为TP，其他作为FP。

**FP** : 一个错误的预测，检测的IOU<Threshod或者置信度小于阈值，即预测的边框分类不正确或者是边界框坐标不达标的数量。在预测的边界框中除了TP就是FP了。

**FN**: 没有被检测出来的ground truth。即ground truth中减去被正确预测的边框，剩下的边框数量。

**confidence/sore**: 目标检测时候除了类别，四个坐标，还有confidence或者score，不同的模型叫法不同。不过他们的意思都是指边框包含目标概率的大小。

举个例子，一个图片检测到100个边框，其中包含有A类30个，B类30个，C类40个。如果A类的GT有4个，但是只是有2个被找到了，那么A类的TP为2，FP为28，FN为2。不过这种情况还是比较乐观的，一个来说情况比较复杂，譬如多个预测框都对同一个GT的IOU都大于阈值或者一个预测框对于两个相邻的物体的IOU都大于阈值。

# 如何绘制PR曲线

其实上述所说到的A类别的TP、FP、FN都是都是一个batch累加得到的。也就是一个batch得到了一个A类别的的TP、FP和FN。那样子的话每个类别又怎么能得到一组PR曲线呢？

对于PR值，不同的sore阈值便可以得到不同数量的边框，从而便可以根据计算公式计算出多组PR的数值了。所以说需要多组的PR值，就需要不同的sore阈值，不过在实际操作中，我们不需要手动调整sore阈值，因为每一个框都有一个sore值，譬如A类有100个预测框，那么就会100个sore值了，把sore从大到小排序，分别吧这些sore作为阈值，就有了100组PR值了。

举个例子。第一张图片有2个A类的GT，有3个预测框，sore分别是0.9,0.5,0.3，经匹配，0.9和0.3的预测框与GT匹配，score按照从小到大排序，想metric数组中加入有(0.9,1),(0.5,0),(03,1)。这里的1代表TP，0代表FP。第二图片没有A类物体，但是有A类预测框，sore为0.45，向metric中加入(0.45,0)。第三张图片有1个A类物体，没有预测框。第四张图片有3个A类物体，有5个预测框，有三个与GT匹配，向metric中加入(0.85,1),(0.8,1),(0.7,1),(0.35,0),(0.1,0)。第五张照片没有A类物体，也没有A类物体的预测框。

score从大到小排序，于是有了metirc数组，(0.9,1)，(0.85,1)，(0.8,1)，(0.7,1)，(0.5,1)，(0.45,0)，(0.35,0)，(0.3,1)，(0.1,0)。我们先计算所以的预测框的PR，即score为0，五张图片预测框共有9个，正确预测有5个框，所以P=5/9。因为共6个GT，只能正确预测5个，所以R=5/6。然后依次去掉最有一个组数据，计算PR值。去掉最后一组，预测框共8个，正确预测还是5个，有P=5/8，有R=5/6。继续去掉最后一组，预测框共7个，正确预测4个，所以有P=4/7，R=4/6。依次类推，最后得到9组数据，分别为(5/9,5/6)，(5/8,5/6)，(4/7,4/6)，(4/6,4/6)，(4/5,4/6)，(4/4,4/6)，(3/3,3/6)，(2/2,2/6)，(1/1,1/6)。计算AP时候，同一个R值，我们取最大的P,所以有了6组数据，分别为(5/8,5/6)，(4/7,4/6)，(3/3,3/6)，(2/2,2/6)，(1/1,1/6)。因为有6个GT，所以R的取值范围应为1/6到6/6。因为没有R=6/6，所以去R=6/6时候，P=0。A类的AP值=(1/1+2/2+3/3+4/7+5/8+0)/6=0.7708。按照这个方式计算各个类别的AP值，便得到mAP。跟下面的PASCAL VOC标准大体上差不多。

# PASCAL VOC的AP计算

## 11-point interpolation

把Recall分为0:0.1:1共11个等级，当R=0时候，P。
$$
AP =\frac {1}{11}\displaystyle \sum^{}_{r\in {0.1,0.2...1}}{p_{interp}(r)}
$$
其中
$$
p_{interp}(r)=max^{}_{r':r'>=r}\ p(r')
$$

## Interpolating all points

这方式是计算PR曲线的面积，目的是为了减少曲线摆动的影响。
$$
\displaystyle \sum^{}_{n=0}(r_{n+1}-r_{n}){p_{interp}(r_{n+1})}
$$
其中，
$$
p_{interp}(r_{n+1})=max^{}_{r':r'>=r_{n+1}}\ p(r')
$$
**绘制PR曲线**：每个预测框按照score或者confidence从大到小进行排序，通过累计的方式计算多组PR值。

**相关链接**：https://github.com/rafaelpadilla/Object-Detection-Metrics

## COCO mAP 计算

PASCAL VOC 固定了IOU阈值为0.5,COCO则取不同的的IOU阈值0.5:0.5:0.95，然后平均IOU每个阈值下的mAP







* 