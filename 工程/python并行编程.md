# 第一章 认识并行计算和Python

## 1.介绍

* 提高计算能力的两种思路
  * 提高处理器的时钟速度
  * 增加芯片的核心数

**add**

* CPU时钟保证了指令执行的稳定性，什么时候开始执行某个操作，由脉冲控制。脉冲跑的快一点，执行效率自然会高。

## 2 并行计算的内存框架

* SISD：就像一条流水线，单个处理器，在单一数据流上执行指令，就是一条数据一条数据地顺序执行
* MISD：虽然共享一个内存单元，但是有多个处理器。一条数据同时被多个处理器执行。无啥无用之地。
* SIMD：指令单一的，多个独立处理器，有自己的局部内存。多条数据流，不同的数据流在相同的指令上执行
* MIMD：多指令，多数据，多处理器，每个处理器都可以在不同的数据执行不同的指令

## 3 内存管理

* 制约内存达到处理器速度影响级别的相应事件主要是内存存取周期。因为如果内存存取速度慢的话，就会让处理器等待了。
* 存取周期是连续启动两次读写操作所需要间隔的最小时间。
* 为了解决MIMD架构访问内存问题，提出了两中内存管理系统。
  * 共享内存系统，有大量的虚拟内存空间，每个处理器拥有平等的访问权限。
  * 分布式内存系统，每个处理器都有自己专属的内存，其他处理器都不能访问。
* 对于程序员来说，必须准确区分共享内存和分布式内存，因为并行编程需要根据内存管理方式来确定进程线程的通信方法
  * 对于共享内存来说，子进程访问数据可以直接通过引用
  * 对于分布式，需要在局部内存保存共享数据的副本

### 3.1 共享内存

* 每个处理器都有自己的Cache，以防所需要的数据被修改

* 特性

  * 内存对所有处理器都一样
  * 每次只有一个处理器访问内存

  * 当一个任务正在访问共享内存时候，其他任务都不能改变内存单元的内容
  * 两个任务通信时间和读取一个内存单元的时间相等

* 访问内存方式

  * 均匀内存访问：速度相同
  * 非均匀内存访问：有高速访问区域和低速访问区域
  * 无远程内存访问：
  * 仅Cache可访问：这类系统仅有Cache内存

## 3.2 分布式内存

* 每个处理器都有自己的内存
* 优点
  * 每个处理器都不受其他干扰而充分利用局部内存带宽
  * 处理器数量无限制，只局限于连接处理器的网络带宽
  * 没有Cache一致性问题的困扰

* 缺点
  * 通信困难,，通过消息传递协议来交换消息降低速度
    * 创建、发送和处理消息需要时间
    * 需要停止工作来处理其他处理器的消息
* 特性
  * 局部内存只能由对应处理器访问
  * 同步 控制通过在处理器之间转移数据来实现？
  * 局部内存的数据分支会影响机器性能？
  * 消息传递协议用于CPU间交换数据包通信

* 工作站集群
  * 通过计算机通讯网络连接起来。我纳闷了，那随便都随便两台计算机都可以是集群了，因为都是通过网络连接起来的啊，但是一个任务，普通两台计算机能配合工作吗？不能把。但工作站集群就能。
  * 三种集群
    * 故障切换集群
    * 负载均衡集群
    * 高性能计算集群
* 异构架构
  * CPU将计算密集型和具有高并行性的任务分配给GPU执行
  * CPU和GPU都没有独立的内存空间，通过编程框架(CUDA,OPenCL)来操控内存，这就是异构架构
  * 那我的计算机时异构架构？？？应该不是把，因为GPU由显存？CPU也有寄存器？？

## 4 并行编程模型

* 共享内存模型
  * 优点
    * 不需要清楚任务间通讯细节
  * 缺点
    * 了解和管理数据区域更加困难
* 多线程模型
* 消息传递模型
  * 通常应用在分布式内存系统
* 数据并行
  * 多任务操作同一数据结构但是每个任务操作的时数据的不同部分

## 5 如何设计一个并行程序

* 任务分解
  * 按范围分解：数据分解
  * 按功能分解：任务分解
* 任务分配
  * 负载均衡是关键
    * 考虑异构系统
  * 减少处理器之间的通信
* 聚合
  * 如果任务分解过小，资源消耗大，此时需要聚合
* 映射
  * 指定哪个任务由哪个处理器处理
  * 两个相互矛盾的策略
    * 频繁通讯任务应由一个处理器完成
    * 可以并行的任务应该由多个处理器处理



## 6 如何评估并行程序的性能

* 加速比
* 效率
* 伸缩性
* 啊姆德尔定律：最大加速比被串行部分限制
* 古斯塔夫森定律：S(P)=P-a(P-1)

## 8 并行世界的python

* 提高运行速度
  * 使用C语言编写的第三方库
  * 使用即时编译器PyPy
  * 并行模块

## 9 介绍进程和线程

* 进程可以包括多个并行线程
* 线程比进程更节省资源
* 同一进程下的线程共享地址空间和其他资源，进程之间相互独立

# 第二章 基于线程的并行

## 1 介绍

* 线程包含三要素：
  * 程序计数器
  * 寄存器
  * 栈
* 线程的状态分为：
  * ready
  * running
  * blocked
* 多线程编程一般是使用共享空间进行通信

## 2 使用Python的线程模块

* python 主要通过标准库threading进行管理线程
* 线程模块主要组件
  * 线程对象
  * Lock对象
  * Rlock对象
  * 信号对象
  * 条件对象
  * 事件对象

## 6 使用Lock进行线程同步

* 两个或以上并发编线程对共享内存进行操作，并且有一个至少可以改变数据，又没有同步机制的条件下，就会产生竞争条件
* 竞争条件最简单的解决方法是使用锁。访问共享内存必须先得到锁，才能访问。访问完就释放锁。让其他线程有锁可以拿
* 使用Lock管理线程
  * 操作锁
    * acquire()
    * release()
  * 规则
    * 原状态unlocked
      * 使用acquire将状态改为lock
      * 使用release将导致RuntimeError异常
    * 原状态是locked
      * 使用acquire会被阻塞直到另一线程调用release()
      * 调用release()将状态改为unlocked
* 缺点
  * 引起不必要的开哨，限制程序的可扩展性和可读性
  * 最好使用其他可选方法确保同步读取共享文件，避免竞争条件

## 7 使用RLock进行线程同步

* 如果只想让拿到锁的线程才能该锁，那么应该使用RLock()对象
* Relock对比Lock有三个特点：
  * 谁拿谁释放
  * 同一个线程可以拿多次锁，可以acquire多次
  * acquire多少次就必须release多少次。只有最后一次release才能改变Rlock的状态为unlocked

## 8 使用信号量进行线程同步

* semaphore.acquire
  * 如果要读取关联了信号量的共享资源，就必须要调用acquire(),此操作减少信号量的内部变量，如果变量为非负，就分配资源，如果是负值，线程被挂起，直到有其他线程释放资源。
* semaphore.release
  * 当线程不再需要该共享资源时候，就必须通过release()释放，信号量内部增加，排在最前面的线程拿到共享资源的权限。
* 信号量的计算器为0时候，就会阻塞acquire()方法，直到得到另外一个线程的通知。

## 9 使用事件进行线程同步

* 事件是线程之间用于通信的对象
* 事件内部会维护一个内部变量，通过set设置为true，通过clear设置为flase，
* wait方法会阻塞线程，知道时间内部状态变成true

## 10 使用with语法

* 使用with语法可以在特定的地方分配和释放资源
* 下列对象可以使用with语法
  * Lock
  * RLock
  * Condition
  * Semaphore

## 11 使用queue进行线程通信

* 内置锁机制
* Queue()常用方法
  * put()
  * get()
  * task_done()
  * join()