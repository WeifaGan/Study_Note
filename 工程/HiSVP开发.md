# 1.概述

## 1.1 SVP

SVP是海思上的一个异构加速平台。包含了：

* 硬件
  * CPU
  * DSP
  * NNIE
* SDK开发环境
* 配套的工具链开发环境

这个SVP加速平台是不是可以理解为海思芯片上一个模块呢，然后这个模块包含了一些硬件和SDK和工具链开发环境，用于加速。

## 1.2开发框架

![](https://gitee.com/weifagan/MyPic/raw/master/img/hi.PNG)

不同的硬件有不同的工具链，我们在使用应用程序时候要结合这些工具进行开发。

## 1.3 硬件资源

不同的SVP有不同的硬件资源。

我们使用的是Hi3559AV100.

* CPU包含两个双核，
  * 双核A73
  * 双核A53
* 4个DSP
* 2个NNIE

## 1.4 软件开发

SVP需要结合MPP平台一起进行软件开发。

## 1.5 开发环境

不同芯片的SVP需要在不同的环境上运行。

我们公司用的Hi3559AV100的SVP运行环境是Linux(big.LITTLE/Multi-Core)



# 3 NNIE开发指南

## 3.1 NNIE介绍

NNIE是海思对神经网络加速的硬件单元。仅支持Caffe框架。

### 3.1.1 工具链介绍

SVP NNIE在HiSVP_PC_Vxxx.rar组件中，包含

* nnie_mapper:生成数据指令文件(.wk)，将我们开源框架得到的转化为可以在海思芯片上或者仿真库上可以加载的数据指令文件。也就是说其他模型转成caffe模型，caffe模型再转.wk文件，才能仿真库加载。
* 仿真库：模拟niee硬件执行和软件接口调用。
* 仿真Sample工程：用于学习参考
* 模型包：仿真Sample工程用到的模型及其其他所需文件。
* WINDOW版本的IDE工具RuyiStdio。集成了niee_wapper和仿真库。



### 3.1.2 开发流程

在仿真库上进行仿真，对精度、性能和带宽进行初步评估。觉得ok，再上板子。也就是说训练得到的精度跟部署在板子上精度可能会不一样(不然也不让仿真了)，那么精度的丢失可能是由于哪些方面造成。

* caffe模型通过mapper离线转换成.wk文件
* 加载.wk文件
* 输入预测的图片

### 3.1.3 网络层分类

niee支持：

* caffe标准层
* 扩展层：基于caffe框架自定义的层

niee不支持：

* Caffe专用于训练的层，非caffe框架的层

### 3.1.4 扩展层规则

为了使wrapper支持扩展层的网络，需要对原始的caffe进行扩展。

如果对原始caffe进行扩展先不看了，有需要再看。



### 3.1.5 Non-support层处理方式

对于不支持的层，需要分段执行，将不支持放在SVP的CPU或者DSP上执行。具体怎么分段先不学习。

nnie将NNIE不支持的层分成两种：

* Proposal层：输出的是矩形信息
* Custom层：输出是tensor

### 3.1.7 NNIE硬件资源利用率

可以使用一下准则提高硬件利用率

* 总体原则
  * 一般情况下，相同计算量的场景，尽量增加单层的计算量，减少网络层数，可以较少层间切换到利用率损失
  * 尽量使用卷积，反卷积，Pooling、FC层。减少LRN、MVN、Normalize、softmax的使用
  * 使用RELU、Sigmoid，tanh、PRELU、RRELU激活函数并使用inplace。
* 特别地：略

## 3.4 Linux版NNIE mapper安装

略

## 3.5 Linux版本nnie使用说明

nnie版本说明:

| 芯片        | nnie版本 | mapper版本                                           |
| ----------- | -------- | ---------------------------------------------------- |
| Hi3559AV100 | nnie1.1  | nnie_mapper_11(cpu版本)、nnie_mapper_gpu_11(GPU版本) |

## 3.6仿真库使用说明

NNIE仿真库分为功能仿真、指令仿真和性能仿真

* 功能仿真是指从功能一致性的角度进行仿真
* 指令仿真是指从指令一致性的角度进行仿真
* 性能仿真输出各层的带宽、cycle数仿真结果；性能仿真模型跟指令仿真一并执行

功能仿真、指令仿真和硬件的结果保持一致。

# 3.7 NNIE调试

上板或者仿真库结果不对或者精度不正常， 参考下面的步骤进行问题定位

* 预处理一致性问题
* 多断网络输入问题
* 精度下降问题
  * 用不同的方法打印不同的层的结果，定位问题
    * 例如指令仿真、功能

# 5 RuyiStudio工具开发指南

RS集成了NNIE mapper和仿真库，同时也有代码编辑 编译 调试 执行功能和显示网络拓扑图等。

## 5.3 生成wk功能

要生成wk，就要配置好.cfg配置文件，再配置.cfg文件之前我们当然也要确保模型是正确的，所以RuyiStudio也提供了关于.prototxt的功能，例如prototxt标记功能，可视化功能，prototxt可视化属性编辑(指定某些层做CPU运算，高精度层，中间上报层)。

cfg配置好后就可以生成wk了，会生成两个文件mapper_quant，mappeer_param。其中mapper_quant包括了：

量化后bias,weights,input,反量化后weight,input。还有反量化input得到的output。

mapper_param包含了来自caffe模型的参数。



## 5.4 NNIE仿真

上面讲的wk功能就是NNIE仿真服务的。有了NNIE和CPP代码，那么就可以进行NNIE仿真了。

NNIE仿真主要：

* 功能仿真
* 指令仿真
  * 根据麦工的意思，指令仿真才能在嵌入式上跑。

## 5.5 数据分析工具

数据分析功能：

* 网络拓扑图显示功能
* 向量相似性比较功能
* 调试定位信息获取功能：获取有问题的网络层
* 目标检测功能
* 输出caffe中间结果功能

* dump出来的网络层还原

### 5.5.2 向量相似性比较功能

比较不同功能配置的每一层向量的相似度，可以帮助我们定位哪个环节进入精度误差。

不同的配置包括：

* caffe推理
* nnie_mapper量化以及反量化bypass后推理结果
* 指令仿真推理结果
* 上板推理结果
* 功能仿真结果

TODO:

* 不太懂如何通过不同配置的对比来定位哪个环节有精度误差?
* 根据麦工的说法，我们是原来的caffe模型做对比。

### 5.5.7芯片高效模式和Un-inplace功能

* 芯片高效模式是把符合某些规范的层改成inplace模式
* 当然也可以把所有inplace(多层或单层)改成un-inplace
* 恢复prototxt原始功能
* 保存修改后的prototxt功能
* 仿真性能展示(cycle仿)
* 拓扑图对比功能

## 5.7 Fine Tune辅助添加量化层

修改prototxt模型，增加量化层，然后做训练。



**Question:**

1.NIEE仿真结果是量化后的吗？

我想法：我猜不一定，可以量化可以不量化。如果我需要量化的结果，那应该是添加量化层。

问了麦工后：NIEE仿真结果是量化后的结果(作整型)。

2.添加量化层需不需要重新训练？

我的想法：应该不用，应该只是浮点型变成整型，那么量化就一定是整型的量化吗？

问了麦工后：假如量化后的结果相差比较大，那么可能会考虑加入量化层进行训练，得到新的结果。

我问出这两个问题，说明我之前是没有搞明白量化和量化层。加了层就是要重新训练了，量化就是对结果做整型处理。